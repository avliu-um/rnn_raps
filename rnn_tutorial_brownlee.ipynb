{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30533b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1d418db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_RNN(hidden_units, dense_units, input_shape, activation):\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(hidden_units, input_shape=input_shape, \n",
    "                        activation=activation[0]))\n",
    "    model.add(Dense(units=dense_units, activation=activation[1]))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba7f9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualize RNN with toy example\n",
    "\n",
    "demo_model = create_RNN(2, 1, (3,1), activation=['linear', 'linear'])\n",
    "\n",
    "wx = demo_model.get_weights()[0]\n",
    "wh = demo_model.get_weights()[1]\n",
    "bh = demo_model.get_weights()[2]\n",
    "wy = demo_model.get_weights()[3]\n",
    "by = demo_model.get_weights()[4]\n",
    "\n",
    "print('wx = ', wx, ' wh = ', wh, ' bh = ', bh, ' wy =', wy, 'by = ', by)\n",
    "\n",
    "x = np.array([1, 2, 3])\n",
    "# Reshape the input to the required sample_size x time_steps x features \n",
    "x_input = np.reshape(x,(1, 3, 1))\n",
    "y_pred_model = demo_model.predict(x_input)\n",
    "\n",
    "\n",
    "m = 2\n",
    "h0 = np.zeros(m)\n",
    "h1 = np.dot(x[0], wx) + h0 + bh\n",
    "h2 = np.dot(x[1], wx) + np.dot(h1,wh) + bh\n",
    "h3 = np.dot(x[2], wx) + np.dot(h2,wh) + bh\n",
    "o3 = np.dot(h3, wy) + by\n",
    "\n",
    "print('h1 = ', h1,'h2 = ', h2,'h3 = ', h3)\n",
    "\n",
    "print(\"Prediction from network \", y_pred_model)\n",
    "print(\"Prediction from our computation \", o3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e91c759e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter split_percent defines the ratio of training examples\n",
    "def get_train_test(url, split_percent=0.8):\n",
    "    df = read_csv(url, usecols=[1], engine='python')\n",
    "    data = np.array(df.values.astype('float32'))\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    data = scaler.fit_transform(data).flatten()\n",
    "    n = len(data)\n",
    "    # Point for splitting data into train and test\n",
    "    split = int(n*split_percent)\n",
    "    train_data = data[range(split)]\n",
    "    test_data = data[split:]\n",
    "    return train_data, test_data, data\n",
    "\n",
    "sunspots_url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/monthly-sunspots.csv'\n",
    "train_data, test_data, data = get_train_test(sunspots_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27ac8cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_csv(sunspots_url, usecols=[1], engine='python')\n",
    "data = np.array(df.values.astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "035e062e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the input X and target Y\n",
    "def get_XY(dat, time_steps):\n",
    "    # Indices of target array\n",
    "    Y_ind = np.arange(time_steps, len(dat), time_steps)\n",
    "    Y = dat[Y_ind]\n",
    "    # Prepare X\n",
    "    rows_x = len(Y)\n",
    "    X = dat[range(time_steps*rows_x)]\n",
    "    X = np.reshape(X, (rows_x, time_steps, 1))    \n",
    "    return X, Y\n",
    "\n",
    "time_steps = 12\n",
    "trainX, trainY = get_XY(train_data, time_steps)\n",
    "testX, testY = get_XY(test_data, time_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b6400af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "187/187 - 1s - loss: 0.0266 - 645ms/epoch - 3ms/step\n",
      "Epoch 2/20\n",
      "187/187 - 0s - loss: 0.0113 - 348ms/epoch - 2ms/step\n",
      "Epoch 3/20\n",
      "187/187 - 0s - loss: 0.0080 - 259ms/epoch - 1ms/step\n",
      "Epoch 4/20\n",
      "187/187 - 0s - loss: 0.0066 - 199ms/epoch - 1ms/step\n",
      "Epoch 5/20\n",
      "187/187 - 0s - loss: 0.0057 - 199ms/epoch - 1ms/step\n",
      "Epoch 6/20\n",
      "187/187 - 0s - loss: 0.0052 - 202ms/epoch - 1ms/step\n",
      "Epoch 7/20\n",
      "187/187 - 0s - loss: 0.0048 - 195ms/epoch - 1ms/step\n",
      "Epoch 8/20\n",
      "187/187 - 0s - loss: 0.0045 - 198ms/epoch - 1ms/step\n",
      "Epoch 9/20\n",
      "187/187 - 0s - loss: 0.0043 - 203ms/epoch - 1ms/step\n",
      "Epoch 10/20\n",
      "187/187 - 0s - loss: 0.0042 - 362ms/epoch - 2ms/step\n",
      "Epoch 11/20\n",
      "187/187 - 0s - loss: 0.0040 - 279ms/epoch - 1ms/step\n",
      "Epoch 12/20\n",
      "187/187 - 0s - loss: 0.0040 - 210ms/epoch - 1ms/step\n",
      "Epoch 13/20\n",
      "187/187 - 0s - loss: 0.0038 - 202ms/epoch - 1ms/step\n",
      "Epoch 14/20\n",
      "187/187 - 0s - loss: 0.0038 - 201ms/epoch - 1ms/step\n",
      "Epoch 15/20\n",
      "187/187 - 0s - loss: 0.0037 - 307ms/epoch - 2ms/step\n",
      "Epoch 16/20\n",
      "187/187 - 0s - loss: 0.0037 - 365ms/epoch - 2ms/step\n",
      "Epoch 17/20\n",
      "187/187 - 0s - loss: 0.0037 - 272ms/epoch - 1ms/step\n",
      "Epoch 18/20\n",
      "187/187 - 0s - loss: 0.0036 - 229ms/epoch - 1ms/step\n",
      "Epoch 19/20\n",
      "187/187 - 0s - loss: 0.0036 - 220ms/epoch - 1ms/step\n",
      "Epoch 20/20\n",
      "187/187 - 0s - loss: 0.0036 - 206ms/epoch - 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb779582940>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_RNN(hidden_units=3, dense_units=1, input_shape=(time_steps,1), \n",
    "                   activation=['tanh', 'tanh'])\n",
    "model.fit(trainX, trainY, epochs=20, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8dbf6111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Train RMSE: 0.058 RMSE\n",
      "Test RMSE: 0.085 RMSE\n"
     ]
    }
   ],
   "source": [
    "def print_error(trainY, testY, train_predict, test_predict):    \n",
    "    # Error of predictions\n",
    "    train_rmse = math.sqrt(mean_squared_error(trainY, train_predict))\n",
    "    test_rmse = math.sqrt(mean_squared_error(testY, test_predict))\n",
    "    # Print RMSE\n",
    "    print('Train RMSE: %.3f RMSE' % (train_rmse))\n",
    "    print('Test RMSE: %.3f RMSE' % (test_rmse))    \n",
    "\n",
    "# make predictions\n",
    "train_predict = model.predict(trainX)\n",
    "test_predict = model.predict(testX)\n",
    "# Mean square error\n",
    "print_error(trainY, testY, train_predict, test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9c3dd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
